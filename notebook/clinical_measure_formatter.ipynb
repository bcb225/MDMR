{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c207d67-310e-494c-b716-ebe41067b9e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/changbae/fmri_project/MDMR/notebook/data/id_lookup_table.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_386818/418676042.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the id_lookup_table and demographics DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mid_lookup_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/changbae/fmri_project/MDMR/notebook/data/id_lookup_table.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdemographics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/changbae/fmri_project/MDMR/notebook/data/demographics.xlsx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/changbae/fmri_project/MDMR/notebook/data/id_lookup_table.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the id_lookup_table and demographics DataFrame\n",
    "id_lookup_table = pd.read_csv(\"/home/changbae/fmri_project/MDMR/notebook/data/id_lookup_table.csv\")\n",
    "demographics = pd.read_excel(\"/home/changbae/fmri_project/MDMR/notebook/data/demographics.xlsx\", skiprows=1, header=0)\n",
    "\n",
    "scores_xls = pd.ExcelFile(\"/home/changbae/fmri_project/MDMR/notebook/data/scores.xlsx\")\n",
    "\n",
    "# Load score sheets\n",
    "STAI_X_1 = scores_xls.parse(\"STAI_X_1\")\n",
    "STAI_X_2 = scores_xls.parse(\"STAI_X_2\")\n",
    "HADS = scores_xls.parse(\"HADS\")\n",
    "SWLS = scores_xls.parse(\"SWLS\")\n",
    "GAD_7 = scores_xls.parse(\"GAD_7\")\n",
    "PDSS = scores_xls.parse(\"PDSS\")\n",
    "LSAS = scores_xls.parse(\"LSAS\")\n",
    "MOCI = scores_xls.parse(\"MOCI\")\n",
    "BFNE = scores_xls.parse(\"BFNE\")\n",
    "PSWQ = scores_xls.parse(\"PSWQ\")\n",
    "FCV_19S = scores_xls.parse(\"FCV_19S\")\n",
    "HANDEDNESS = scores_xls.parse(\"HANDEDNESS_수정\")\n",
    "\n",
    "# Rename columns\n",
    "demographics.columns = [\n",
    "    'GROUP', 'Exp No.', 'Chart No.', '이름', '1. SEX', '2.AGE', '3-1. EDU', '3-2. YR_EDU', \n",
    "    '4. JOB', '5. SES', '정신질환 가족/친척 유무', '참가자와 관계', '정신과입원유무', '질환명', \n",
    "    '현재 질병 유무', '병명', '과거 뇌외상/뇌질환', '정신질환 유무', '병명2', '입원횟수', \n",
    "    '첫 정신과적 입원 (몇년 전)', '첫 정신과적 입원 (입원 년도)', '발병시기 (몇년 전)', \n",
    "    '발병시기 (입원 년도)', '항정신병 약물', '향정신병약물/ 용량(mg/tab)', '용량(tab)', \n",
    "    '현 용량 시작일', '기타 약물(약품명/용량)', '총 약물 치료기간', '비고'\n",
    "]\n",
    "\n",
    "# Define the function to generate fmri codes\n",
    "def generate_fmri_code(row):\n",
    "    prefix = 's' if row['GROUP'] == 'EXP' else 'c'\n",
    "    return f\"{prefix}{int(row['Exp No.']):04d}\"\n",
    "\n",
    "# Apply the function to each row\n",
    "demographics['fmri_code'] = demographics.apply(generate_fmri_code, axis=1)\n",
    "\n",
    "# Merge the two DataFrames on fmri_code\n",
    "merged_df = pd.merge(demographics, id_lookup_table, on=['fmri_code'], how='left')\n",
    "\n",
    "# Drop rows where fmri_code is NaN\n",
    "filtered_df = merged_df.dropna(subset=['fmri_code'])\n",
    "\n",
    "# Convert 'HAID ID' to string for consistent merging\n",
    "filtered_df['HAID ID'] = filtered_df['HAID ID'].astype(str)\n",
    "\n",
    "# Function to extract data from each score sheet\n",
    "def extract_scores(sheet, score_columns):\n",
    "    scores_dict = {}\n",
    "    sheet_filtered = sheet[sheet['round'] == 1]\n",
    "    for _, row in sheet_filtered.iterrows():\n",
    "        haid_id = str(row['id'])\n",
    "        if haid_id not in scores_dict:\n",
    "            scores_dict[haid_id] = {}\n",
    "        for col in score_columns:\n",
    "            scores_dict[haid_id][col] = row[col]\n",
    "    return scores_dict\n",
    "\n",
    "# Extract data from each sheet\n",
    "score_data = {\n",
    "    'STAI-X-1': extract_scores(STAI_X_1, ['STAI-X-1']),\n",
    "    'STAI-X-2': extract_scores(STAI_X_2, ['STAI-X-2']),\n",
    "    'HADS_anxiety': extract_scores(HADS, ['HADS_anxiety']),\n",
    "    'HADS_depression': extract_scores(HADS, ['HADS_depression']),\n",
    "    'SWLS': extract_scores(SWLS, ['SWLS']),\n",
    "    'GAD-7': extract_scores(GAD_7, ['GAD-7']),\n",
    "    'PDSS': extract_scores(PDSS, ['PDSS']),\n",
    "    'performance_lsas': extract_scores(LSAS, ['performance_lsas']),\n",
    "    'social_interaction_lsas': extract_scores(LSAS, ['social_interaction_lsas']),\n",
    "    'lsas': extract_scores(LSAS, ['lsas']),\n",
    "    'MOCI': extract_scores(MOCI, ['MOCI']),\n",
    "    'checking': extract_scores(MOCI, ['checking']),\n",
    "    'cleaning': extract_scores(MOCI, ['cleaning']),\n",
    "    'doubting': extract_scores(MOCI, ['doubting']),\n",
    "    'slowness': extract_scores(MOCI, ['slowness']),\n",
    "    'BFNE': extract_scores(BFNE, ['BFNE']),\n",
    "    'PSWQ': extract_scores(PSWQ, ['PSWQ']),\n",
    "    'Handedness(true)': extract_scores(HANDEDNESS, ['Handedness(true)']),\n",
    "    'FCV-19S': extract_scores(FCV_19S, ['FCV-19S'])\n",
    "}\n",
    "\n",
    "# Add scores to the filtered dataframe\n",
    "for haid_id in filtered_df['HAID ID']:\n",
    "    for key, data in score_data.items():\n",
    "        if haid_id in data:\n",
    "            filtered_df.loc[filtered_df['HAID ID'] == haid_id, key] = data[haid_id][key]\n",
    "\n",
    "# Select the final columns to keep in the resulting DataFrame\n",
    "final_columns = [\n",
    "    '1. SEX', '2.AGE', '3-2. YR_EDU', 'fmri_code', 'Screening #', 'Enrollment #', 'HAID ID',\n",
    "    'STAI-X-1', 'STAI-X-2', 'HADS_anxiety', 'HADS_depression', 'SWLS', 'GAD-7', 'PDSS', 'performance_lsas', \n",
    "    'social_interaction_lsas', 'lsas', 'MOCI', 'checking', 'cleaning', 'doubting', 'slowness', 'BFNE', \n",
    "    'PSWQ', 'Handedness(true)', 'FCV-19S'\n",
    "]\n",
    "\n",
    "final_df = filtered_df[final_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90a65ae9-f84d-4ebb-8391-f9a3c8100092",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"/home/changbae/fmri_project/MDMR/notebook/data/participant_demo_clinical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "429638e4-0789-4359-b9e0-baf7209a581a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values count for each column:\n",
      "1. SEX                      0\n",
      "2.AGE                       0\n",
      "3-2. YR_EDU                 3\n",
      "fmri_code                   0\n",
      "Screening #                46\n",
      "Enrollment #               46\n",
      "HAID ID                     0\n",
      "STAI-X-1                   53\n",
      "STAI-X-2                   53\n",
      "HADS_anxiety               54\n",
      "HADS_depression            54\n",
      "SWLS                       54\n",
      "GAD-7                      54\n",
      "PDSS                       54\n",
      "performance_lsas           54\n",
      "social_interaction_lsas    54\n",
      "lsas                       54\n",
      "MOCI                       54\n",
      "checking                   54\n",
      "cleaning                   54\n",
      "doubting                   54\n",
      "slowness                   54\n",
      "BFNE                       54\n",
      "PSWQ                       54\n",
      "Handedness(true)           53\n",
      "FCV-19S                    54\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 각 열의 결측치 개수를 계산\n",
    "missing_values_count = final_df.isnull().sum()\n",
    "\n",
    "# 결측치 개수 출력\n",
    "print(\"Missing values count for each column:\")\n",
    "print(missing_values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7fc31671-db60-4982-968f-d75ae018e2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ID count in id_lookup_table: 119\n",
      "\n",
      "Sheet: STAI_X_1\n",
      "Unique ID count in sheet: 160\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: STAI_X_2\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: HADS_anxiety\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: HADS_depression\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: SWLS\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: GAD_7\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: PDSS\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: performance_lsas\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: social_interaction_lsas\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: lsas\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: MOCI\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: checking\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: cleaning\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: doubting\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: slowness\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: BFNE\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: PSWQ\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: Handedness(true)\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n",
      "\n",
      "Sheet: FCV_19S\n",
      "Unique ID count in sheet: 159\n",
      "Common ID count with id_lookup_table: 112\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the id_lookup_table and demographics DataFrame\n",
    "id_lookup_table = pd.read_csv(\"/home/changbae/fmri_project/MDMR/notebook/data/id_lookup_table.csv\")\n",
    "\n",
    "# Load the scores data from the Excel file\n",
    "scores_xls = pd.ExcelFile(\"/home/changbae/fmri_project/MDMR/notebook/data/scores.xlsx\")\n",
    "\n",
    "# STAI-X-1\n",
    "STAI_X_1 = scores_xls.parse(\"STAI_X_1\")\n",
    "\n",
    "# STAI-X-2\n",
    "STAI_X_2 = scores_xls.parse(\"STAI_X_2\")\n",
    "\n",
    "# HADS_anxiety, HADS_depression\n",
    "HADS = scores_xls.parse(\"HADS\")\n",
    "\n",
    "# SWLS\n",
    "SWLS = scores_xls.parse(\"SWLS\")\n",
    "\n",
    "# GAD_7\n",
    "GAD_7 = scores_xls.parse(\"GAD_7\")\n",
    "\n",
    "# PDSS\n",
    "PDSS = scores_xls.parse(\"PDSS\")\n",
    "\n",
    "# performance_lsas, social_interaction_lsas, lsas\n",
    "LSAS = scores_xls.parse(\"LSAS\")\n",
    "\n",
    "# MOCI, checking, cleaning, doubting, slowness\n",
    "MOCI = scores_xls.parse(\"MOCI\")\n",
    "\n",
    "# BFNE\n",
    "BFNE = scores_xls.parse(\"BFNE\")\n",
    "\n",
    "# PSWQ\n",
    "PSWQ = scores_xls.parse(\"PSWQ\")\n",
    "\n",
    "# FCV_19S\n",
    "FCV_19S = scores_xls.parse(\"FCV_19S\")\n",
    "\n",
    "# Handedness(true)\n",
    "HANDEDNESS = scores_xls.parse(\"HANDEDNESS_수정\")\n",
    "\n",
    "# Get unique ids from id_lookup_table\n",
    "lookup_unique_ids = set(id_lookup_table['HAID ID'].astype(str).unique())\n",
    "print(f\"Unique ID count in id_lookup_table: {len(lookup_unique_ids)}\")\n",
    "\n",
    "# Function to get unique ids from a sheet\n",
    "def get_unique_ids(sheet):\n",
    "    return set(sheet['id'].astype(str).unique())\n",
    "\n",
    "# List of score sheets\n",
    "score_sheets = [\n",
    "    ('STAI_X_1', STAI_X_1),\n",
    "    ('STAI_X_2', STAI_X_2),\n",
    "    ('HADS_anxiety', HADS),\n",
    "    ('HADS_depression', HADS),\n",
    "    ('SWLS', SWLS),\n",
    "    ('GAD_7', GAD_7),\n",
    "    ('PDSS', PDSS),\n",
    "    ('performance_lsas', LSAS),\n",
    "    ('social_interaction_lsas', LSAS),\n",
    "    ('lsas', LSAS),\n",
    "    ('MOCI', MOCI),\n",
    "    ('checking', MOCI),\n",
    "    ('cleaning', MOCI),\n",
    "    ('doubting', MOCI),\n",
    "    ('slowness', MOCI),\n",
    "    ('BFNE', BFNE),\n",
    "    ('PSWQ', PSWQ),\n",
    "    ('Handedness(true)', HANDEDNESS),\n",
    "    ('FCV_19S', FCV_19S)\n",
    "]\n",
    "\n",
    "# Check each sheet for unique ids and matches with id_lookup_table\n",
    "for sheet_name, sheet in score_sheets:\n",
    "    sheet_unique_ids = get_unique_ids(sheet)\n",
    "    common_ids = sheet_unique_ids.intersection(lookup_unique_ids)\n",
    "    print(f\"\\nSheet: {sheet_name}\")\n",
    "    print(f\"Unique ID count in sheet: {len(sheet_unique_ids)}\")\n",
    "    print(f\"Common ID count with id_lookup_table: {len(common_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "93740870-5ab9-4ba1-9577-96e8bf1bce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'HAID ID' to string for consistent merging\n",
    "filtered_df['HAID ID'] = filtered_df['HAID ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "37c83921-d2a2-4537-9064-2501bb9f1bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_xls = pd.ExcelFile(\"/home/changbae/fmri_project/MDMR/notebook/data/scores.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d0781d99-b0dd-4002-a4f0-652826ee475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming filtered_df is already defined and the dataframes for each sheet are already loaded\n",
    "\n",
    "# Define a function to extract scores\n",
    "def extract_scores(df, columns, id):\n",
    "    extracted_col = df[(df['id'] == id) & (df['round'] == 1)][columns]\n",
    "    if len(extracted_col.values) == 0:\n",
    "        return \"n/a\"\n",
    "    else:\n",
    "        return extracted_col.values[0][0]\n",
    "\n",
    "# Dictionary to hold the extracted scores for each id\n",
    "extracted_scores = []\n",
    "\n",
    "# Loop through each unique HAID ID and extract the scores for each sheet\n",
    "for id in filtered_df['HAID ID'].unique():\n",
    "    target_filtered_df = filtered_df[filtered_df['HAID ID'] == id]\n",
    "    score_dict = {\n",
    "        'HAID ID': id,\n",
    "        'GROUP': target_filtered_df['GROUP'].values[0],\n",
    "        'Exp No.': target_filtered_df['Exp No.'].values[0],\n",
    "        '1. SEX': target_filtered_df['1. SEX'].values[0],\n",
    "        '2.AGE': target_filtered_df['2.AGE'].values[0],\n",
    "        '3-2. YR_EDU': target_filtered_df['3-2. YR_EDU'].values[0],\n",
    "        'fmri_code': target_filtered_df['fmri_code'].values[0],\n",
    "        'Screening #': target_filtered_df['Screening #'].values[0],\n",
    "        'Enrollment #': target_filtered_df['Enrollment #'].values[0],\n",
    "\n",
    "        \n",
    "        'STAI-X-1': extract_scores(STAI_X_1, ['STAI-X-1'], id),\n",
    "        'STAI-X-2': extract_scores(STAI_X_2, ['STAI-X-2(true)'], id),\n",
    "        'HADS_anxiety': extract_scores(HADS, ['HADS_anxiety'], id),\n",
    "        'HADS_depression': extract_scores(HADS, ['HADS_depression'], id),\n",
    "        'SWLS': extract_scores(SWLS, ['SWLS(true)'], id),\n",
    "        'GAD-7': extract_scores(GAD_7, ['GAD-7(true변환)'], id),\n",
    "        'PDSS': extract_scores(PDSS, ['PDSS'], id),\n",
    "        'LSAS_performance': extract_scores(LSAS, ['performance_lsas'], id),\n",
    "        'LSAS_social_interaction': extract_scores(LSAS, ['social_interaction_lsas'], id),\n",
    "        'LSAS': extract_scores(LSAS, ['lsas'], id),\n",
    "        'MOCI': extract_scores(MOCI, ['MOCI'], id),\n",
    "        'MOCI_checking': extract_scores(MOCI, ['checking'], id),\n",
    "        'MOCI_cleaning': extract_scores(MOCI, ['cleaning'], id),\n",
    "        'MOCI_doubting': extract_scores(MOCI, ['doubting'], id),\n",
    "        'MOCI_slowness': extract_scores(MOCI, ['slowness'], id),\n",
    "        'BFNE': extract_scores(BFNE, ['BFNE(ture)'], id),\n",
    "        'PSWQ': extract_scores(PSWQ, ['PSWQ(true)'], id),\n",
    "        'Handedness(true)': extract_scores(HANDEDNESS, ['Handedness(true)'], id),\n",
    "        'FCV-19S': extract_scores(FCV_19S, ['FCV(ttrue)'], id)\n",
    "    }\n",
    "    extracted_scores.append(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "26c54413-49e4-4541-a237-ea0ec139a1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GROUP', 'Exp No.', 'Chart No.', '이름_x', '1. SEX', '2.AGE', '3-1. EDU',\n",
       "       '3-2. YR_EDU', '4. JOB', '5. SES', '정신질환 가족/친척 유무', '참가자와 관계',\n",
       "       '정신과입원유무', '질환명', '현재 질병 유무', '병명', '과거 뇌외상/뇌질환', '정신질환 유무', '병명2',\n",
       "       '입원횟수', '첫 정신과적 입원 (몇년 전)', '첫 정신과적 입원 (입원 년도)', '발병시기 (몇년 전)',\n",
       "       '발병시기 (입원 년도)', '항정신병 약물', '향정신병약물/ 용량(mg/tab)', '용량(tab)', '현 용량 시작일',\n",
       "       '기타 약물(약품명/용량)', '총 약물 치료기간', '비고', 'fmri_code', 'Unnamed: 0',\n",
       "       'Screening #', 'Enrollment #', 'HAID ID', '이름_y', 'STAI-X-1',\n",
       "       'STAI-X-2', 'HADS_anxiety', 'HADS_depression', 'SWLS', 'GAD-7', 'PDSS',\n",
       "       'performance_lsas', 'social_interaction_lsas', 'lsas', 'MOCI',\n",
       "       'checking', 'cleaning', 'doubting', 'slowness', 'BFNE', 'PSWQ',\n",
       "       'Handedness(true)', 'FCV-19S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0d258450-52f0-47ad-adb5-b55e0c06f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_scores_df = pd.DataFrame(extracted_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e8e823ca-76dc-4fa5-96f5-5a0e8bd61fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HAID ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>Exp No.</th>\n",
       "      <th>1. SEX</th>\n",
       "      <th>2.AGE</th>\n",
       "      <th>3-2. YR_EDU</th>\n",
       "      <th>fmri_code</th>\n",
       "      <th>Screening #</th>\n",
       "      <th>Enrollment #</th>\n",
       "      <th>STAI-X-1</th>\n",
       "      <th>...</th>\n",
       "      <th>LSAS</th>\n",
       "      <th>MOCI</th>\n",
       "      <th>MOCI_checking</th>\n",
       "      <th>MOCI_cleaning</th>\n",
       "      <th>MOCI_doubting</th>\n",
       "      <th>MOCI_slowness</th>\n",
       "      <th>BFNE</th>\n",
       "      <th>PSWQ</th>\n",
       "      <th>Handedness(true)</th>\n",
       "      <th>FCV-19S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0827jck</td>\n",
       "      <td>EXP</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>12.0</td>\n",
       "      <td>s0007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>EXP-0001</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>na0840</td>\n",
       "      <td>EXP</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>12.0</td>\n",
       "      <td>s0005</td>\n",
       "      <td>2.0</td>\n",
       "      <td>EXP-0002</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>40</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spwls915</td>\n",
       "      <td>EXP</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>15.0</td>\n",
       "      <td>s0004</td>\n",
       "      <td>3.0</td>\n",
       "      <td>EXP-0003</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wkddbswns</td>\n",
       "      <td>HC</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>15.0</td>\n",
       "      <td>c0009</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HC-0001</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bje5409</td>\n",
       "      <td>EXP</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>12.0</td>\n",
       "      <td>s0012</td>\n",
       "      <td>5.0</td>\n",
       "      <td>EXP-0004</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>hong94</td>\n",
       "      <td>HC</td>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>15.0</td>\n",
       "      <td>c0552</td>\n",
       "      <td>151.0</td>\n",
       "      <td>HC-0071</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>sunset</td>\n",
       "      <td>HC</td>\n",
       "      <td>546</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>16.0</td>\n",
       "      <td>c0546</td>\n",
       "      <td>152.0</td>\n",
       "      <td>HC-0072</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>bpark0718</td>\n",
       "      <td>HC</td>\n",
       "      <td>547</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>c0547</td>\n",
       "      <td>154.0</td>\n",
       "      <td>HC-0073</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>robin4760</td>\n",
       "      <td>HC</td>\n",
       "      <td>518</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>12.0</td>\n",
       "      <td>c0518</td>\n",
       "      <td>156.0</td>\n",
       "      <td>HC-0074</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>yyyyjg</td>\n",
       "      <td>HC</td>\n",
       "      <td>549</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c0549</td>\n",
       "      <td>167.0</td>\n",
       "      <td>HC-0076</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HAID ID GROUP  Exp No.  1. SEX  2.AGE  3-2. YR_EDU fmri_code  \\\n",
       "0      0827jck   EXP        7       2     20         12.0     s0007   \n",
       "1       na0840   EXP        5       2     20         12.0     s0005   \n",
       "2     spwls915   EXP        4       2     21         15.0     s0004   \n",
       "3    wkddbswns    HC        9       1     25         15.0     c0009   \n",
       "4      bje5409   EXP       12       2     30         12.0     s0012   \n",
       "..         ...   ...      ...     ...    ...          ...       ...   \n",
       "114     hong94    HC      552       1     29         15.0     c0552   \n",
       "115     sunset    HC      546       1     29         16.0     c0546   \n",
       "116  bpark0718    HC      547       2     28         12.0     c0547   \n",
       "117  robin4760    HC      518       2     25         12.0     c0518   \n",
       "118     yyyyjg    HC      549       2     35          NaN     c0549   \n",
       "\n",
       "     Screening # Enrollment # STAI-X-1  ... LSAS MOCI MOCI_checking  \\\n",
       "0            1.0     EXP-0001     56.0  ...   98   19             4   \n",
       "1            2.0     EXP-0002     67.0  ...   80   15             5   \n",
       "2            3.0     EXP-0003     65.0  ...   95   18             6   \n",
       "3            4.0      HC-0001     35.0  ...   18   24             7   \n",
       "4            5.0     EXP-0004     55.0  ...   57   26             8   \n",
       "..           ...          ...      ...  ...  ...  ...           ...   \n",
       "114        151.0      HC-0071     30.0  ...   13    2             2   \n",
       "115        152.0      HC-0072     43.0  ...   19    8             2   \n",
       "116        154.0      HC-0073     32.0  ...   45    8             3   \n",
       "117        156.0      HC-0074     32.0  ...    8    5             1   \n",
       "118        167.0      HC-0076     34.0  ...   24    4             1   \n",
       "\n",
       "    MOCI_cleaning MOCI_doubting MOCI_slowness BFNE PSWQ Handedness(true)  \\\n",
       "0               8             5             4   56   58               48   \n",
       "1               6             3             2   57   62               40   \n",
       "2              10             1             5   59   60               40   \n",
       "3              11             3             7   35   47               47   \n",
       "4              11             4             7   51   50               47   \n",
       "..            ...           ...           ...  ...  ...              ...   \n",
       "114             0             0             0   29   33               43   \n",
       "115             1             4             1   40   30               40   \n",
       "116             0             3             2   43   25               42   \n",
       "117             0             4             0   38   37               41   \n",
       "118             0             2             1   41   45               46   \n",
       "\n",
       "    FCV-19S  \n",
       "0         7  \n",
       "1        18  \n",
       "2         5  \n",
       "3         2  \n",
       "4         4  \n",
       "..      ...  \n",
       "114       0  \n",
       "115       2  \n",
       "116       2  \n",
       "117       4  \n",
       "118       0  \n",
       "\n",
       "[119 rows x 28 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "51f1614b-8245-4a2a-9e6b-0136666f0802",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_scores_df.to_csv(\"/home/changbae/fmri_project/MDMR/notebook/data/participant_demo_clinical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c943e95-b303-4e61-baf3-e41aa8e7ed1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa0acae-3986-4f9b-bb45-4af269f2666a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
